{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(type='cuda',index=0)\n",
    "else:\n",
    "    device=torch.device(type='cpu',index=0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de' #German\n",
    "TGT_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the tokenizer for German and English\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "\n",
    "#function to yield list of tokens for building the vocab\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    if language=='de':\n",
    "        for data_sample in data_iter:\n",
    "            yield de_tokenizer(data_sample[0])\n",
    "    elif language=='en':\n",
    "        for data_sample in data_iter:\n",
    "            yield en_tokenizer(data_sample[1])\n",
    "            \n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "#build vocab for German\n",
    "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "\n",
    "#torchtext.datasets.Multi30k(root: str = '.data', \n",
    "#split: Union[Tuple[str], str] = ('train', 'valid', 'test'), \n",
    "#language_pair: Tuple[str] = ('de', 'en')). Available options are (‘de’,’en’) and (‘en’, ‘de’)\n",
    "\n",
    "#train: 29000, #valid: 1014, #test: 1000\n",
    "\n",
    "#Returns DataPipe that yields tuple of source and target sentences (str,str)\n",
    "\n",
    "vocab_de=build_vocab_from_iterator(yield_tokens(train_iter, 'de'),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "vocab_de.set_default_index(UNK_IDX)\n",
    "\n",
    "\n",
    "#Now, build vocab for English\n",
    "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "vocab_en=build_vocab_from_iterator(yield_tokens(train_iter, 'en'),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "vocab_en.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.vocab.vocab.Vocab'>\n",
      "English Vocab Length: 10837\n",
      "German Vocab Length: 19214\n"
     ]
    }
   ],
   "source": [
    "print(type(vocab_en))\n",
    "print(\"English Vocab Length:\",vocab_en.__len__())\n",
    "print(\"German Vocab Length:\",vocab_de.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare separate batch for source sentence ids and target sentence ids\n",
    "#insert <EOS> in source sentence\n",
    "#insert <BOS> and <EOS> in target sentence\n",
    "#pad sentences in a batch to same length\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        \n",
    "        src_sample=src_sample.rstrip(\"\\n\") #string\n",
    "        tgt_sample=tgt_sample.rstrip(\"\\n\")\n",
    "        \n",
    "        src_tokens=de_tokenizer(src_sample) #sentence/string to list of word tokens\n",
    "        tgt_tokens=en_tokenizer(tgt_sample)\n",
    "        \n",
    "        src_ids=vocab_de(src_tokens) #from list of word tokens to list of ids\n",
    "        tgt_ids=vocab_en(tgt_tokens)\n",
    "        \n",
    "        src_ids.append(EOS_IDX) #append <EOS> to list\n",
    "        tgt_ids.append(EOS_IDX)\n",
    "        \n",
    "        tgt_ids.insert(0,BOS_IDX) #start with <BOS> in list\n",
    "        \n",
    "        src_tensor=torch.tensor(src_ids) #convert to tensor\n",
    "        tgt_tensor=torch.tensor(tgt_ids)\n",
    "        \n",
    "        \n",
    "        src_batch.append(src_tensor) #list of tensors\n",
    "        tgt_batch.append(tgt_tensor)\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True) #returns tensor\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.e=nn.Embedding(input_size, embed_size)\n",
    "        self.dropout=nn.Dropout(dropout_p)\n",
    "        self.gru=nn.GRU(embed_size,hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.e(x)\n",
    "        x=self.dropout(x)\n",
    "        outputs, hidden=self.gru(x)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,output_size,embed_size,hidden_size):\n",
    "        super().__init__()\n",
    "        self.e=nn.Embedding(output_size,embed_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.gru=nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.lin=nn.Linear(hidden_size,output_size)\n",
    "        self.lsoftmax=nn.LogSoftmax(dim=-1)\n",
    "    \n",
    "    def forward(self,x,prev_hidden):\n",
    "        x=self.e(x)\n",
    "        x=self.relu(x)\n",
    "        output,hidden=self.gru(x,prev_hidden)\n",
    "        y=self.lin(output)\n",
    "        y=self.lsoftmax(y)\n",
    "        return y, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    track_loss=0\n",
    "    \n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    for i, (s_ids,t_ids) in enumerate(train_dataloader):\n",
    "        \n",
    "        s_ids=s_ids.to(device)\n",
    "        t_ids=t_ids.to(device)\n",
    "        encoder_outputs, encoder_hidden=encoder(s_ids)\n",
    "        decoder_hidden=encoder_hidden\n",
    "        yhats, decoder_hidden = decoder(t_ids[:,0:-1],decoder_hidden)\n",
    "                    \n",
    "        gt=t_ids[:,1:]\n",
    "        \n",
    "        yhats_reshaped=yhats.view(-1,yhats.shape[-1])\n",
    "        \n",
    "        gt=gt.reshape(-1)\n",
    "        \n",
    "        \n",
    "        loss=loss_fn(yhats_reshaped,gt)\n",
    "        track_loss+=loss.item()\n",
    "        \n",
    "        opte.zero_grad()\n",
    "        optd.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opte.step()\n",
    "        optd.step()\n",
    "        \n",
    "    return track_loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval loop (written assuming batch_size=1)\n",
    "def eval_one_epoch(e,n_epochs):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    track_loss=0\n",
    "    \n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=1, collate_fn=collate_fn)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (s_ids,t_ids) in enumerate(val_dataloader):\n",
    "            s_ids=s_ids.to(device) # [1, source sequence length]\n",
    "            t_ids=t_ids.to(device)\n",
    "            encoder_outputs, encoder_hidden=encoder(s_ids)\n",
    "            decoder_hidden=encoder_hidden #n_dim=3\n",
    "            input_id=t_ids[:,0] #shape is just [1]\n",
    "            yhats=[]\n",
    "            if e+1==n_epochs:\n",
    "                pred_sentence=\"\"\n",
    "            for j in range(1,t_ids.shape[1]): #j starts from 1 #iterates for len(t_ids)-1 times as the last id is of <EOS>\n",
    "                probs, decoder_hidden = decoder(input_id.unsqueeze(1),decoder_hidden) #need batch_size x seq_length\n",
    "                yhats.append(probs)\n",
    "                _,input_id=torch.topk(probs,1,dim=-1)\n",
    "                input_id=input_id.squeeze(1,2) #still a tensor\n",
    "                if e+1==n_epochs:                    \n",
    "                    word=vocab_en.lookup_token(input_id.item()) #batch_size=1\n",
    "                    pred_sentence+=word + \" \"\n",
    "                if input_id.item() == 3: #batch_size=1 #Id 3 is <EOS>\n",
    "                    break\n",
    "                                \n",
    "            if e+1==n_epochs:\n",
    "                src_sentence_tokens=vocab_de.lookup_tokens(s_ids.tolist()[0])\n",
    "                src_sentence=\" \".join(src_sentence_tokens)\n",
    "                gt_sentence_tokens=vocab_en.lookup_tokens(t_ids[:,1:].tolist()[0])\n",
    "                gt_sentence=\" \".join(gt_sentence_tokens)\n",
    "                print(\"\\n-----------------------------------\")\n",
    "                print(\"Source Sentence:\",src_sentence)\n",
    "                print(\"GT Sentence:\",gt_sentence)\n",
    "                print(\"Predicted Sentence:\",pred_sentence)\n",
    "            \n",
    "            yhats_cat=torch.cat(yhats,dim=1)\n",
    "            yhats_reshaped=yhats_cat.view(-1,yhats_cat.shape[-1])\n",
    "            gt=t_ids[:,1:j+1] #shape is [1, target sequence length -1] #as <BOS> is not part of GT\n",
    "            \n",
    "            gt=gt.view(-1) #shape is [target sequence length -1]\n",
    "            \n",
    "            loss=loss_fn(yhats_reshaped,gt)\n",
    "            track_loss+=loss.item()\n",
    "            \n",
    "        if e+1==n_epochs:    \n",
    "            print(\"-----------------------------------\")\n",
    "        return track_loss/(i+1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch=\u001b[39m\u001b[38;5;124m\"\u001b[39m,e\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss=\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;241m4\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval Loss=\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mround\u001b[39m(eval_one_epoch(e,n_epochs),\u001b[38;5;241m4\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m gt\u001b[38;5;241m=\u001b[39mt_ids[:,\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     19\u001b[0m yhats_reshaped\u001b[38;5;241m=\u001b[39myhats\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,yhats\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m gt\u001b[38;5;241m=\u001b[39m\u001b[43mgt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m loss\u001b[38;5;241m=\u001b[39mloss_fn(yhats_reshaped,gt)\n\u001b[0;32m     25\u001b[0m track_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_size=300\n",
    "hidden_size=512\n",
    "batch_size=32\n",
    "\n",
    "encoder=Encoder(vocab_de.__len__(),embed_size,hidden_size).to(device) #translation-direction sensitive\n",
    "decoder=Decoder(vocab_en.__len__(),embed_size,hidden_size).to(device) #translation-direction sensitive\n",
    "\n",
    "loss_fn=nn.NLLLoss(ignore_index=1).to(device)\n",
    "lr=0.001\n",
    "opte=optim.Adam(params=encoder.parameters(), lr=lr, weight_decay=0.001)\n",
    "optd=optim.Adam(params=decoder.parameters(), lr=lr, weight_decay=0.001)\n",
    "\n",
    "n_epochs=20\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    print(\"Epoch=\",e+1, sep=\"\", end=\", \")\n",
    "    print(\"Train Loss=\", round(train_one_epoch(),4), sep=\"\", end=\", \")\n",
    "    print(\"Eval Loss=\",round(eval_one_epoch(e,n_epochs),4), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
